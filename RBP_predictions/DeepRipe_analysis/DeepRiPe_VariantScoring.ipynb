{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepRiPe_VariantScoring.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "18yeqRE7KmOjfbUaLAfJ6rMBjAulYo-Uc",
      "authorship_tag": "ABX9TyPmQHN3QVQm4TZlXWQR2zwn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcortes-lopez/CD19_splicing_mutagenesis/blob/main/DeepRiPe_VariantScoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5AQRLwuNdeE"
      },
      "source": [
        "Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKE8m8sYGW-j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "b05eec56-3fd2-4d00-c7a3-75c0c1bce00e"
      },
      "source": [
        "pip install concise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting concise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/0b/b3bf80e9898cba65ab27629d5cfd28975c962af910c996bc6e8566ca91d1/concise-0.6.9-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from concise) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from concise) (1.18.5)\n",
            "Collecting gtfparse>=1.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/5c/8bd2e9020051ccffc60c56ae70b32a3b649ddac1962e9aa641f93542440e/gtfparse-1.2.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from concise) (0.22.2.post1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from concise) (1.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from concise) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from concise) (1.0.5)\n",
            "Collecting keras<=2.2.4,>=2.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: descartes in /usr/local/lib/python3.6/dist-packages (from concise) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->concise) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->concise) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->concise) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->concise) (1.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->concise) (0.15.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->concise) (2018.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras<=2.2.4,>=2.0.4->concise) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.2.4,>=2.0.4->concise) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras<=2.2.4,>=2.0.4->concise) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras<=2.2.4,>=2.0.4->concise) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras<=2.2.4,>=2.0.4->concise) (1.0.8)\n",
            "Building wheels for collected packages: gtfparse\n",
            "  Building wheel for gtfparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gtfparse: filename=gtfparse-1.2.0-cp36-none-any.whl size=11883 sha256=0eba7df807ac032880a073a355368661e0077d9d81569e506cb4306a89b21c53\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/27/96/6ba6fe28cbb162c326823553e3e45ac502160d1340566360f8\n",
            "Successfully built gtfparse\n",
            "Installing collected packages: gtfparse, keras, concise\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed concise-0.6.9 gtfparse-1.2.0 keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SSNzF1gPBax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "5e8b4739-cc36-4a59-b615-4dca2aa147e2"
      },
      "source": [
        "!git clone https://github.com/ohlerlab/DeepRiPe.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepRiPe'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 795 (delta 1), reused 12 (delta 1), pack-reused 777\u001b[K\n",
            "Receiving objects: 100% (795/795), 476.59 MiB | 15.42 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "Checking out files: 100% (602/602), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCybi7cdHRI1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "a3eea4b2-fa4e-49be-ec0f-62c8ffb4af0a"
      },
      "source": [
        "pip install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.30.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (47.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=8325944c8df5482eb96a3b69a63098eec961a159104e502e2aeae66a3420a2ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCqlw--wSvKr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "b412d0d2-1fa4-4a21-e294-d809634cd069"
      },
      "source": [
        "!apt-get install bedtools\n",
        "\n",
        "!pip install pybedtools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  bedtools\n",
            "0 upgraded, 1 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 577 kB of archives.\n",
            "After this operation, 2,040 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 bedtools amd64 2.26.0+dfsg-5 [577 kB]\n",
            "Fetched 577 kB in 2s (284 kB/s)\n",
            "Selecting previously unselected package bedtools.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../bedtools_2.26.0+dfsg-5_amd64.deb ...\n",
            "Unpacking bedtools (2.26.0+dfsg-5) ...\n",
            "Setting up bedtools (2.26.0+dfsg-5) ...\n",
            "Collecting pybedtools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/14/152220f39cda6b9b72810eeed103c6ec78422429adabe3aafc3eaf6feb40/pybedtools-0.8.1.tar.gz (12.5MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5MB 334kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pybedtools) (1.12.0)\n",
            "Collecting pysam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/a1/73e80a7a873f3fb0e52d368a4343eb9882b737c932b95020d82251f1087e/pysam-0.16.0.1-cp36-cp36m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 21.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pybedtools\n",
            "  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybedtools: filename=pybedtools-0.8.1-cp36-cp36m-linux_x86_64.whl size=13605480 sha256=69b3aa192797bf1068d154e304acde4079d7627da6991b586ce73a77dc11ddce\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/50/97/7d0e4f605d0d1578997f4bba3061869c2dee9f8cd29f626323\n",
            "Successfully built pybedtools\n",
            "Installing collected packages: pysam, pybedtools\n",
            "Successfully installed pybedtools-0.8.1 pysam-0.16.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A_z_2_uBs_S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "c3978b0d-2350-44a5-f7dd-fe1a3da4fa4b"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import scipy.io\n",
        "np.random.seed(7) # for reproducibility\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Model, load_model\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import pybedtools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"DeepRiPe/Scripts/\")\n",
        "from IntegratedGradients import *\n",
        "from util_funcs import *\n",
        "from plotseqlogo import seqlogo_fig_cross\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "2020-07-01 19:02:21,141 [INFO] Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "2020-07-01 19:02:21,170 [INFO] Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:21,717 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "DeepRiPe/Scripts/plotseqlogo.py:44: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  min_coords = np.vstack(data.min(0) for data in polygons_data).min(0)\n",
            "DeepRiPe/Scripts/plotseqlogo.py:45: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  max_coords = np.vstack(data.max(0) for data in polygons_data).max(0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFFAyiquJQyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75a1f73d-f86d-4e60-fa2d-b194eb0cd829"
      },
      "source": [
        "def precision(y_true, y_pred):\n",
        "\ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "\t#TPs=K.sum(K.round(K.clip(y_true * y_pred , 0, 1)))\n",
        "\tpredicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "\tprecision = true_positives / (predicted_positives + K.epsilon())\n",
        "\treturn precision\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "\ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "\t#TPs=K.sum(K.round(K.clip(y_ture * y_pred , 0, 1)))\n",
        "\tpossible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "\trecall = true_positives / (possible_positives + K.epsilon())\n",
        "\treturn recall\n",
        "\n",
        "\n",
        "\n",
        "RBPnames_low=np.array(['MBNL1', 'P53_NONO', 'PUM2', 'QKI', 'AGO3', 'FUS', 'TAF15', 'ZFP36', 'DICER1', 'EIF3A', 'EIF3D', 'EIF3G', 'SSB', 'PAPD5', 'CPSF4', 'CPSF3', 'RTCB', 'FXR1', 'NOP58', 'NOP56', 'FBL', 'LIN28A', 'LIN28B', 'UPF1', 'G35', 'G45', 'XPO5'])\n",
        "RBPnames_med=np.array(['TARDBP', 'ELAVL2', 'ELAVL3', 'ELAVL4', 'RBM20', 'IGF2BP1', 'IGF2BP2', 'IGF2BP3', 'EWSR1', 'HNRNPD', 'RBPMS', 'SRRM4', 'AGO2', 'NUDT21', 'FIP1L1', 'CAPRIN1', 'FMR1iso7', 'FXR2', 'AGO1', 'L1RE1', 'ORF1'])\n",
        "RBPnames_high=np.array(['DND1', 'CPSF7', 'CPSF6', 'CPSF1', 'CSTF2', 'CSTF2T', 'ZC3H7B', 'FMR1iso1', 'RBM10', 'MOV10', 'ELAVL1'])\n",
        "\n",
        "\n",
        "path_to_model = \"DeepRiPe/Results/PARCLIP_models/\"\n",
        "path_to_modelhigh= path_to_model + \"model_RBPshigh.h5\"\n",
        "path_to_modelmed= path_to_model + \"model_RBPsmed.h5\"\n",
        "path_to_modellow= path_to_model + \"model_RBPslow.h5\"\n",
        "\n",
        "\n",
        "model_high=load_model(path_to_modelhigh, custom_objects={'precision': precision,'recall': recall }) \n",
        "igres_high = integrated_gradients(model_high) \n",
        "\n",
        "model_med=load_model(path_to_modelmed, custom_objects={'precision': precision,'recall': recall }) \n",
        "igres_med = integrated_gradients(model_med) \n",
        "\n",
        "model_low=load_model(path_to_modellow, custom_objects={'precision': precision,'recall': recall }) \n",
        "igres_low = integrated_gradients(model_low)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:21,786 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:21,797 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:21,836 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:21,844 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:21,847 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:21,864 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,003 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,004 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,006 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,133 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,137 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,167 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,238 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,246 [WARNING] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,578 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-01 19:02:22,844 [WARNING] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Xl0uZaTFsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "2513b7fb-5c00-4bc9-c0d4-a9f725ff1a2c"
      },
      "source": [
        "def precision(y_true, y_pred):\n",
        "\ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "\t#TPs=K.sum(K.round(K.clip(y_true * y_pred , 0, 1)))\n",
        "\tpredicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "\tprecision = true_positives / (predicted_positives + K.epsilon())\n",
        "\treturn precision\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "\ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "\t#TPs=K.sum(K.round(K.clip(y_ture * y_pred , 0, 1)))\n",
        "\tpossible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "\trecall = true_positives / (possible_positives + K.epsilon())\n",
        "\treturn recall\n",
        "\n",
        "\n",
        "\n",
        "RBPnames_low=np.array(['MBNL1', 'P53_NONO', 'PUM2', 'QKI', 'AGO3', 'FUS', 'TAF15', 'ZFP36', 'DICER1', 'EIF3A', 'EIF3D', 'EIF3G', 'SSB', 'PAPD5', 'CPSF4', 'CPSF3', 'RTCB', 'FXR1', 'NOP58', 'NOP56', 'FBL', 'LIN28A', 'LIN28B', 'UPF1', 'G35', 'G45', 'XPO5'])\n",
        "RBPnames_med=np.array(['TARDBP', 'ELAVL2', 'ELAVL3', 'ELAVL4', 'RBM20', 'IGF2BP1', 'IGF2BP2', 'IGF2BP3', 'EWSR1', 'HNRNPD', 'RBPMS', 'SRRM4', 'AGO2', 'NUDT21', 'FIP1L1', 'CAPRIN1', 'FMR1iso7', 'FXR2', 'AGO1', 'L1RE1', 'ORF1'])\n",
        "RBPnames_high=np.array(['DND1', 'CPSF7', 'CPSF6', 'CPSF1', 'CSTF2', 'CSTF2T', 'ZC3H7B', 'FMR1iso1', 'RBM10', 'MOV10', 'ELAVL1'])\n",
        "\n",
        "\n",
        "path_to_model = \"DeepRiPe/Results/PARCLIP_models/\"\n",
        "path_to_modelhigh= path_to_model + \"model_RBPshigh.h5\"\n",
        "path_to_modelmed= path_to_model + \"model_RBPsmed.h5\"\n",
        "path_to_modellow= path_to_model + \"model_RBPslow.h5\"\n",
        "\n",
        "\n",
        "model_high=load_model(path_to_modelhigh, custom_objects={'precision': precision,'recall': recall }) \n",
        "igres_high = integrated_gradients(model_high) \n",
        "\n",
        "model_med=load_model(path_to_modelmed, custom_objects={'precision': precision,'recall': recall }) \n",
        "igres_med = integrated_gradients(model_med) \n",
        "\n",
        "model_low=load_model(path_to_modellow, custom_objects={'precision': precision,'recall': recall }) \n",
        "igres_low = integrated_gradients(model_low)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaaOgaEzp2t-"
      },
      "source": [
        "## ENCODE models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4791h3hp6kF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "6d46ba06-74cc-4b05-c3c2-ab5336dafe5a"
      },
      "source": [
        "\n",
        "\n",
        "K562_path_to_model = \"DeepRiPe/Results/Encode_models/K562/\"\n",
        "K562_path_to_modellow= K562_path_to_model + \"eclip_model_encodeK562_low.h5\"\n",
        "K562_path_to_modelmid1= K562_path_to_model + \"eclip_model_encodeK562_mid1.h5\"\n",
        "K562_path_to_modelmid2= K562_path_to_model + \"eclip_model_encodeK562_mid2.h5\"\n",
        "K562_path_to_modelhigh1= K562_path_to_model + \"eclip_model_encodeK562_high1.h5\"\n",
        "K562_path_to_modelhigh2= K562_path_to_model + \"eclip_model_encodeK562_high2.h5\"\n",
        "\n",
        "K562_RBPnames_low=np.array(['MTPAP', 'RBM22', 'DHX30', 'DDX6', 'DDX55', 'TRA2A', 'XRN2', 'U2AF1', 'LSM11', 'ZC3H11A', 'NOLC1', 'KHDRBS1', 'GPKOW', 'DGCR8', 'AKAP1', 'FXR1', 'DDX52', 'AATF'])\n",
        "K562_RBPnames_mid1=np.array(['U2AF2', 'AKAP8L', 'METAP2', 'SMNDC1', 'GEMIN5', 'HNRNPK', 'SLTM', 'SRSF1', 'FMR1', 'SAFB2', 'DROSHA', 'RPS3', 'IGF2BP2', 'ILF3', 'RBFOX2', 'QKI', 'PCBP1', 'ZNF800', 'PUM1'])\n",
        "K562_RBPnames_mid2=np.array(['EFTUD2', 'LIN28B', 'AGGF1', 'HNRNPL', 'SND1', 'GTF2F1', 'EIF4G2', 'TIA1', 'TARDBP', 'FXR2', 'HNRNPM', 'IGF2BP1', 'PUM2', 'FAM120A', 'DDX3X', 'MATR3', 'FUS', 'GRWD1', 'PABPC4'])\n",
        "K562_RBPnames_high1=np.array(['BUD13', 'PTBP1', 'DDX24', 'EWSR1', 'RBM15'])\n",
        "K562_RBPnames_high2=np.array(['SF3B4', 'YBX3', 'UCHL5', 'KHSRP', 'ZNF622', 'NONO', 'EXOSC5', 'PRPF8', 'CSTF2T', 'AQR', 'UPF1'])\n",
        "\n",
        "K562_RBP_low=load_model(K562_path_to_modellow, custom_objects={'precision': precision,'recall': recall }) \n",
        "K562_RBP_mid1=load_model(K562_path_to_modelmid1, custom_objects={'precision': precision,'recall': recall })\n",
        "K562_RBP_mid2=load_model(K562_path_to_modelmid2, custom_objects={'precision': precision,'recall': recall }) \n",
        "K562_RBP_high1=load_model(K562_path_to_modelhigh1, custom_objects={'precision': precision,'recall': recall }) \n",
        "K562_RBP_high2=load_model(K562_path_to_modelhigh2, custom_objects={'precision': precision,'recall': recall }) \n",
        "\n",
        "K562_igres_low = integrated_gradients(K562_RBP_low)\n",
        "K562_igres_mid1 = integrated_gradients(K562_RBP_mid1)\n",
        "K562_igres_mid2 = integrated_gradients(K562_RBP_mid2)\n",
        "K562_igres_high1 = integrated_gradients(K562_RBP_high1)\n",
        "K562_igres_high2 = integrated_gradients(K562_RBP_high2)\n",
        "\n",
        "\n",
        "HepG2_path_to_model = \"DeepRiPe/Results/Encode_models/HepG2/\"\n",
        "HepG2_path_to_modellow= HepG2_path_to_model + \"eclip_model_encodeHepG2_low.h5\"\n",
        "HepG2_path_to_modelmid1= HepG2_path_to_model + \"eclip_model_encodeHepG2_mid1.h5\"\n",
        "HepG2_path_to_modelmid2= HepG2_path_to_model + \"eclip_model_encodeHepG2_mid2.h5\"\n",
        "HepG2_path_to_modelhigh1= HepG2_path_to_model + \"eclip_model_encodeHepG2_high1.h5\"\n",
        "HepG2_path_to_modelhigh2= HepG2_path_to_model + \"eclip_model_encodeHepG2_high2.h5\"\n",
        "\n",
        "\n",
        "HepG2_RBPnames_low=np.array(['RBM22', 'GRSF1', 'CDC40', 'NOLC1', 'FKBP4', 'DGCR8', 'ZC3H11A', 'XRN2', 'SLTM', 'DDX55', 'TIA1', 'SRSF1', 'U2AF1', 'RBM15'])\n",
        "HepG2_RBPnames_mid1=np.array(['LSM11', 'NKRF', 'SUB1', 'NCBP2', 'UCHL5', 'LIN28B', 'IGF2BP3', 'SF3A3', 'AGGF1', 'DROSHA', 'DDX59', 'CSTF2', 'DKC1', 'EIF3H', 'FUBP3', 'SFPQ', 'HNRNPC', 'ILF3', 'TIAL1', 'HLTF', 'ZNF800', 'PABPN1', 'YBX3', 'FXR2'])\n",
        "HepG2_RBPnames_mid2=np.array(['GTF2F1', 'IGF2BP1', 'HNRNPK', 'XPO5', 'RPS3', 'SF3B4', 'LARP4', 'BUD13', 'SND1', 'G3BP1', 'AKAP1', 'KHSRP'])\n",
        "HepG2_RBPnames_high1=np.array(['DDX3X', 'PCBP2', 'FAM120A', 'HNRNPL', 'RBFOX2', 'PTBP1', 'MATR3', 'EFTUD2', 'PRPF4', 'UPF1'])\n",
        "HepG2_RBPnames_high2= np.array(['GRWD1', 'PRPF8', 'PPIG', 'CSTF2T', 'QKI', 'U2AF2', 'SUGP2', 'HNRNPM', 'AQR', 'BCLAF1'])\n",
        "  \n",
        "HepG2_RBP_low=load_model(HepG2_path_to_modellow, custom_objects={'precision': precision,'recall': recall }) \n",
        "HepG2_RBP_mid1=load_model(HepG2_path_to_modelmid1, custom_objects={'precision': precision,'recall': recall })\n",
        "HepG2_RBP_mid2=load_model(HepG2_path_to_modelmid2, custom_objects={'precision': precision,'recall': recall }) \n",
        "HepG2_RBP_high1=load_model(HepG2_path_to_modelhigh1, custom_objects={'precision': precision,'recall': recall }) \n",
        "HepG2_RBP_high2=load_model(HepG2_path_to_modelhigh2, custom_objects={'precision': precision,'recall': recall }) \n",
        "\n",
        "HepG2_igres_low = integrated_gradients(HepG2_RBP_low)\n",
        "HepG2_igres_mid1 = integrated_gradients(HepG2_RBP_mid1)\n",
        "HepG2_igres_mid2 = integrated_gradients(HepG2_RBP_mid2)\n",
        "HepG2_igres_high1 = integrated_gradients(HepG2_RBP_high1)\n",
        "HepG2_igres_high2 = integrated_gradients(HepG2_RBP_high2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n",
            "Evaluated output channel (0-based index): All\n",
            "Building gradient functions\n",
            "Progress: 100.0%\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn4j3FprVQE0"
      },
      "source": [
        "##Function to prepare the input for the model from variants bedfile\n",
        "##The bedfile should be as follows : chr\tstart\tend\t  variant_name    W/M     strand  where(start=end)\n",
        "\n",
        "def encode_variant_bedline(bedline,genomefasta,flank_size=75):\n",
        "    mut_a = bedline[4].split(\"/\")[1]\n",
        "    strand = bedline[5]\n",
        "    if len(mut_a)==1:\n",
        "        wild = pybedtools.BedTool(bedline[0] + \"\\t\" + str(int(bedline[1])-flank_size) + \"\\t\"  + str(int(bedline[2])+flank_size) + \"\\t\" + \n",
        "                                  bedline[3] + \"\\t\" + str(mut_a) + \"\\t\" + bedline[5], from_string=True )\n",
        "        if strand == \"-\" :\n",
        "            mut_pos= flank_size\n",
        "        else:\n",
        "            mut_pos= flank_size-1\n",
        "                            \n",
        "        #wild = pybedtools.BedTool(bedline[0] + \"\\t\" + bedline[1] + \"\\t\" + bedline[2] + \"\\t\" + bedline[3] + \"\\t\"+ bedline[4] + \"\\t\" + bedline[5], from_string=True)\n",
        "        wild = wild.sequence(fi=genomefasta, tab=True, s=True)\n",
        "        fastalist = open(wild.seqfn).read().split(\"\\n\")\n",
        "        del fastalist[-1]\n",
        "        seqs=[fasta.split(\"\\t\")[1] for fasta in fastalist]\n",
        "        mut=seqs[0]\n",
        "        mut = list(mut)\n",
        "        mut[mut_pos] = mut_a\n",
        "        mut = \"\".join(mut)\n",
        "        seqs.append(mut)\n",
        "        encoded_seqs =np.array([seq_to_1hot(seq) for seq in seqs])\n",
        "        encoded_seqs = np.transpose(encoded_seqs,axes=(0,2,1))\n",
        "        return(encoded_seqs)\n",
        "                   \n",
        "    \n",
        "\n",
        "\n",
        "##Function to score variants using models with both sequence and region \n",
        "def score_variant_withregion(model,RBP_index,variant_bed,genomefasta,tr=0.1):\n",
        "    reg_coded = np.full((250, 4), 0.25)\n",
        "    region=np.array([reg_coded,reg_coded])\n",
        "    score_list = []\n",
        "    bed_list = []\n",
        "    seqs_list = []\n",
        "    for bedline in variant_bed:\n",
        "        encoded_seqs = encode_variant_bedline(bedline,genomefasta)\n",
        "        if encoded_seqs is not None:\n",
        "            pred = model.predict([encoded_seqs,region])[:,RBP_index]\n",
        "            score = (pred[1]-pred[0])\n",
        "            if abs(score) > tr:\n",
        "                score_list.append(score)\n",
        "                bed_list.append(bedline)\n",
        "                seqs_list.append(encoded_seqs)\n",
        "    return(score_list,bed_list,seqs_list)\n",
        "\n",
        "\n",
        "####Function to score variants using models with only sequence\n",
        "def score_variant_onlyseq(model,RBP_index,variant_bed,genomefasta,tr=0.1):\n",
        "    score_list = []\n",
        "    bed_list = []\n",
        "    seqs_list = []\n",
        "    for bedline in variant_bed:\n",
        "        encoded_seqs = encode_variant_bedline(bedline,genomefasta)\n",
        "        if encoded_seqs is not None:\n",
        "            pred = model.predict(encoded_seqs)[:,RBP_index]\n",
        "            score = (pred[1]-pred[0])\n",
        "            if abs(score) > tr:\n",
        "                score_list.append(score)\n",
        "                bed_list.append(bedline)\n",
        "                seqs_list.append(encoded_seqs)\n",
        "    return(score_list,bed_list,seqs_list) \n",
        "\n",
        "\n",
        "####Function to plot attribution map for variant using models with both sequence and region \n",
        "def plot_variant_map_withregion(bedlines,igres,RBP_index,genomefasta,figsave_path=\"\"):\n",
        "    for bedline in bedlines[0:bedlines.count()]:\n",
        "        encoded_seqs = encode_variant_bedline(bedline,genomefasta)\n",
        "        reg_coded = np.full((250, 4), 0.25)\n",
        "        ex_seq = np.array([igres.explain([encoded_seqs[i],reg_coded],outc=RBP_index,reference=False)[0] for i in [0,1]])\n",
        "        plt.close(\"all\")\n",
        "        seqlogo_fig_cross(np.transpose(ex_seq[:,50:100,:4],axes=(1,2,0)), vocab=\"RNA\", figsize=(4,1.5), ncol=1, crosssite=True, cross_positions=[(24.5,25.5),(24.5,25.5),(24.5,25.5)])\n",
        "        #plt.savefig(os.path.join(figsave_path,bedline[3]+\"_\"+str(RBP_index)+\"_region.pdf\"),dpi=300)\n",
        "        #plt.savefig(os.path.join(figsave_path,bedline[3]+\"_\"+str(RBP_index)+\"_region.png\"),dpi=300)\n",
        "        plt.show()\n",
        "        \n",
        "####Function to plot attribution map for variant using models with only sequence\n",
        "def plot_variant_map_onlyseq(bedlines,igres,RBP_index,genomefasta,figsave_path=\"\"):\n",
        "    for bedline in bedlines[0:bedlines.count()]:\n",
        "        encoded_seqs = encode_variant_bedline(bedline,genomefasta)\n",
        "        ex_seq = np.array([igres.explain(encoded_seqs[i],outc=RBP_index,reference=False)[0] for i in [0,1]])\n",
        "        plt.close(\"all\")\n",
        "        seqlogo_fig_cross(np.transpose(ex_seq[:,50:100,:4],axes=(1,2,0)), vocab=\"RNA\", figsize=(4,1.5), ncol=1, crosssite=True, cross_positions=[(24.5,25.5),(24.5,25.5),(24.5,25.5)])\n",
        "        #plt.savefig(os.path.join(figsave_path,bedline[3]+\"_\"+str(RBP_index)+\"_region.pdf\"),dpi=300)\n",
        "        #plt.savefig(os.path.join(figsave_path,bedline[3]+\"_\"+str(RBP_index)+\"_region.png\"),dpi=300)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVuBClO9VgkV"
      },
      "source": [
        "Testing the models with CD19 variants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDGiE_wJ0_K4"
      },
      "source": [
        "#genomefa=\"drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/CD19_WT.minigene.fa\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aES5ABN-Cl6i"
      },
      "source": [
        "Getting the hg38 genome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeR9pDqmCpJs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "5f2ae94c-cb97-4650-b524-3d0ee5098aa1"
      },
      "source": [
        "!wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-01 19:05:25--  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
            "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 983659424 (938M) [application/x-gzip]\n",
            "Saving to: ‘hg38.fa.gz’\n",
            "\n",
            "hg38.fa.gz          100%[===================>] 938.09M  21.5MB/s    in 62s     \n",
            "\n",
            "2020-07-01 19:06:28 (15.2 MB/s) - ‘hg38.fa.gz’ saved [983659424/983659424]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34dO9XvWDCl8"
      },
      "source": [
        "!gunzip hg38.fa.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk53F1b7DSdg"
      },
      "source": [
        "genomefa=\"hg38.fa\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HStV5Evp1RXB"
      },
      "source": [
        "Input some variants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amPd8plUFbs2"
      },
      "source": [
        "### Variants from SNP153 in the minigene region \n",
        "\n",
        "It does not seem to work with the minigene sequence as genome only. Therefore I am trying with the hg38 reference and testing some SNPs in the minigene region."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDQbB-sQFhl3"
      },
      "source": [
        "variant_bed=pybedtools.BedTool('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/all_potential_snps.bed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DlDu3WsF_Hi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "87c508b9-f334-4f17-e162-00e23c4ef1ff"
      },
      "source": [
        "variant_bed.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chr16\t28931871\t28931871\tG1A\tG/A\t+\n",
            " chr16\t28931871\t28931871\tG1C\tG/C\t+\n",
            " chr16\t28931871\t28931871\tG1T\tG/T\t+\n",
            " chr16\t28931872\t28931872\tA2C\tA/C\t+\n",
            " chr16\t28931872\t28931872\tA2G\tA/G\t+\n",
            " chr16\t28931872\t28931872\tA2T\tA/T\t+\n",
            " chr16\t28931873\t28931873\tC3A\tC/A\t+\n",
            " chr16\t28931873\t28931873\tC3G\tC/G\t+\n",
            " chr16\t28931873\t28931873\tC3T\tC/T\t+\n",
            " chr16\t28931874\t28931874\tC4A\tC/A\t+\n",
            " "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz6senMWK20D"
      },
      "source": [
        "### Looping variants across all the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHRzQz1dLskw"
      },
      "source": [
        "def alt_variant_binding(rbpmodel,rbpnames):\n",
        "  model_result = defaultdict(list)   \n",
        "  for rbp in rbpnames:\n",
        "      model = rbpmodel\n",
        "      RBP_index = np.where(rbpnames == rbp)[0][0]\n",
        "      rbp_score_list, rbp_bed_list, rbp_seqs_list = score_variant_withregion(model,RBP_index,variant_bed,genomefa,tr=0.1)\n",
        "      if len(rbp_score_list) != 0:\n",
        "        model_result[rbp].append(rbp_score_list)\n",
        "        model_result[rbp].append(rbp_bed_list)\n",
        "        model_result[rbp].append(rbp_seqs_list) \n",
        "  return(model_result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuPTHhhAlE-u"
      },
      "source": [
        "PAR CLIP models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvHuYeRlixEx"
      },
      "source": [
        "parclip_low_res = alt_variant_binding(model_low, RBPnames_low)\n",
        "parclip_mid_res = alt_variant_binding(model_med, RBPnames_med)\n",
        "parclip_high_res = alt_variant_binding(model_high, RBPnames_high)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4m-43lFlQ5q"
      },
      "source": [
        "eCLIP models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbZH8brO5iuN"
      },
      "source": [
        "##Function to score variants using models with both sequence and region \n",
        "def score_variant_withregion(model,RBP_index,variant_bed,genomefasta,tr=0.1):\n",
        "    reg_coded = np.full((250, 4), 0.25)\n",
        "    region=np.array([reg_coded,reg_coded])\n",
        "    score_list = []\n",
        "    bed_list = []\n",
        "    seqs_list = []\n",
        "    for bedline in variant_bed:\n",
        "        encoded_seqs = encode_variant_bedline(bedline,genomefasta,  flank_size=100)\n",
        "        if encoded_seqs is not None:\n",
        "            pred = model.predict([encoded_seqs,region])[:,RBP_index]\n",
        "            score = (pred[1]-pred[0])\n",
        "            if abs(score) > tr:\n",
        "                score_list.append(score)\n",
        "                bed_list.append(bedline)\n",
        "                seqs_list.append(encoded_seqs)\n",
        "    return(score_list,bed_list,seqs_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkmH96DElTjg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b813744f-17fd-4c0a-d663-0f43b0378e5d"
      },
      "source": [
        "eclip_HepG2_low_res = alt_variant_binding(HepG2_RBP_low, HepG2_RBPnames_low)\n",
        "eclip_HepG2_mid1_res = alt_variant_binding(HepG2_RBP_mid1, HepG2_RBPnames_mid1)\n",
        "eclip_HepG2_mid2_res = alt_variant_binding(HepG2_RBP_mid2, HepG2_RBPnames_mid2)\n",
        "eclip_HepG2_high1_res = alt_variant_binding(HepG2_RBP_high1, HepG2_RBPnames_high1)\n",
        "eclip_HepG2_high2_res = alt_variant_binding(HepG2_RBP_high2, HepG2_RBPnames_high2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index file hg38.fa.fai not found, generating...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTNf2Ti15rLb"
      },
      "source": [
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/HepG2_eclip_low_res.npy', eclip_HepG2_low_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/HepG2_eclip_med1_res.npy', eclip_HepG2_mid1_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/HepG2_eclip_med2_res.npy', eclip_HepG2_mid2_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/HepG2_eclip_high1_res.npy', eclip_HepG2_high1_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/HepG2_eclip_high2_res.npy', eclip_HepG2_high2_res) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb_8sGFHJPBv"
      },
      "source": [
        "eclip_K562_low_res = alt_variant_binding(K562_RBP_low, K562_RBPnames_low)\n",
        "eclip_K562_mid1_res = alt_variant_binding(K562_RBP_mid1, K562_RBPnames_mid1)\n",
        "eclip_K562_mid2_res = alt_variant_binding(K562_RBP_mid2, K562_RBPnames_mid2)\n",
        "eclip_K562_high1_res = alt_variant_binding(K562_RBP_high1, K562_RBPnames_high1)\n",
        "eclip_K562_high2_res = alt_variant_binding(K562_RBP_high2, K562_RBPnames_high2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqvX0XQBOSeN"
      },
      "source": [
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/K562_eclip_low_res.npy', eclip_K562_low_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/K562_eclip_med1_res.npy', eclip_K562_mid1_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/K562_eclip_med2_res.npy', eclip_K562_mid2_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/K562_eclip_high1_res.npy', eclip_K562_high1_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/K562_eclip_high2_res.npy', eclip_K562_high2_res) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQYe8QCBAxjE"
      },
      "source": [
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/parclip_low_res.npy', parclip_low_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/parclip_med_res.npy', parclip_mid_res) \n",
        "np.save('drive/My Drive/CD19_project/RBP_regulators/DeepRiPe_files/parclip_high_res.npy', parclip_high_res) \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}